{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "eIJPwT0IsChG",
        "VfXtrqwjsFhZ",
        "aBKhsOzbcn2M",
        "cCjOLGEL_pyp",
        "c4SvLM3ptVoJ",
        "DbkYjnPqZLzB",
        "bd9kRjJVZNXn",
        "1uy6jj8FZTSu"
      ],
      "machine_shape": "hm",
      "gpuType": "T4",
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Installations"
      ],
      "metadata": {
        "id": "eIJPwT0IsChG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iUDU9QeXr3wL"
      },
      "outputs": [],
      "source": [
        "!pip install -q datasets transformers accelerate fastervit evaluate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm==0.9.12"
      ],
      "metadata": {
        "id": "zHdpJ0rdIp7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "    device_name = torch.device(\"cuda\")\n",
        "else:\n",
        "    device_name = torch.device('cpu')\n",
        "print(\"Using {}.\".format(device_name))"
      ],
      "metadata": {
        "id": "_UMRJsEzTKhI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "VfXtrqwjsFhZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset, DatasetDict, load_metric, Dataset\n",
        "from transformers import AutoImageProcessor, AutoFeatureExtractor, AutoModelForImageClassification, TrainingArguments, Trainer, ViTForImageClassification, ViTFeatureExtractor, ViTImageProcessor, Swinv2Model\n",
        "from torchvision import transforms\n",
        "from sklearn.metrics import accuracy_score, roc_curve, roc_auc_score\n",
        "from sklearn.utils import resample\n",
        "from sklearn.model_selection import train_test_split\n",
        "from fastai.vision.all import *\n",
        "from torchvision.io import read_image\n",
        "from fastervit import create_model\n",
        "from torchvision.transforms import (\n",
        "    CenterCrop,\n",
        "    Compose,\n",
        "    Normalize,\n",
        "    RandomHorizontalFlip,\n",
        "    RandomResizedCrop,\n",
        "    Resize,\n",
        "    ToTensor,\n",
        ")\n",
        "import timm\n",
        "import evaluate\n",
        "import datasets\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import PIL"
      ],
      "metadata": {
        "id": "dwr07oSWsH1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reusable Functions"
      ],
      "metadata": {
        "id": "aBKhsOzbcn2M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels = [\"No Cancer\", \"Cancer\"]\n",
        "label2id, id2label = dict(), dict()\n",
        "for i, label in enumerate(labels):\n",
        "    label2id[label] = i\n",
        "    id2label[i] = label"
      ],
      "metadata": {
        "id": "du48i6OdVcX1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def batch_sampler(examples):\n",
        "    pixel_values = torch.stack([example[\"pixel_values\"] for example in examples])\n",
        "    labels = torch.tensor([example[\"cancer\"] for example in examples])\n",
        "    return {\"pixel_values\": pixel_values, \"labels\": labels}"
      ],
      "metadata": {
        "id": "vzcIKFfeoChT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(labels, preds)\n",
        "\n",
        "   # Calculate precision, recall, and F1-score\n",
        "    precision = precision_score(labels, preds, average='weighted')\n",
        "    recall = recall_score(labels, preds, average='weighted')\n",
        "    f1 = f1_score(labels, preds, average='weighted')\n",
        "\n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1\n",
        "    }"
      ],
      "metadata": {
        "id": "8DOaK0sr6zPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvertToRGB(Transform):\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def encodes(self, x: PIL.Image.Image) -> PIL.Image.Image:\n",
        "        return x.convert('RGB')"
      ],
      "metadata": {
        "id": "-BcC6IzP65Ls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_dataset(data):\n",
        "    dataset = Dataset.from_pandas(data)\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "-l2kL6KWQ_KA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Clean Data"
      ],
      "metadata": {
        "id": "cCjOLGEL_pyp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"Nicole-M/Dataset1\")\n",
        "dataset"
      ],
      "metadata": {
        "id": "9NEc3UZil8Gm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfTrain = pd.DataFrame(dataset['train'])\n",
        "dfVal = pd.DataFrame(dataset['validate'])\n",
        "dfTest = pd.DataFrame(dataset['test'])"
      ],
      "metadata": {
        "id": "z50uLLjn8R3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image Preprocessing"
      ],
      "metadata": {
        "id": "c4SvLM3ptVoJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transforms for pre-processing across a batch.\n",
        "class imageTransform:\n",
        "\n",
        "    def __init__(self, featureExtractor):\n",
        "        size = (featureExtractor.size[\"height\"], featureExtractor.size[\"width\"])\n",
        "        self.transforms = transforms.Compose([\n",
        "            transforms.Resize(size),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.RandomHorizontalFlip(p=0.5),\n",
        "            transforms.RandomVerticalFlip(p=0.5),\n",
        "            transforms.RandomRotation(degrees=180),\n",
        "            transforms.Normalize(mean=featureExtractor.image_mean, std=featureExtractor.image_std),\n",
        "        ])\n",
        "\n",
        "    def __call__(self, example_batch):\n",
        "        example_batch[\"pixel_values\"] = [self.transforms(image.convert(\"RGB\")) for image in example_batch[\"image\"]] # Convert grayscale image to RGB\n",
        "        return example_batch\n"
      ],
      "metadata": {
        "id": "wEpvnIJNtYDn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class valImageTransform:\n",
        "\n",
        "    def __init__(self, featureExtractor):\n",
        "        size = (featureExtractor.size[\"height\"], featureExtractor.size[\"width\"])\n",
        "        self.transforms = transforms.Compose([\n",
        "            transforms.Resize(size),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=featureExtractor.image_mean, std=featureExtractor.image_std),\n",
        "        ])\n",
        "\n",
        "    def __call__(self, example_batch):\n",
        "        example_batch[\"pixel_values\"] = [self.transforms(image.convert(\"RGB\")) for image in example_batch[\"image\"]] # Convert grayscale image to RGB\n",
        "        return example_batch"
      ],
      "metadata": {
        "id": "hHTAnH3YX8xD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VIT model"
      ],
      "metadata": {
        "id": "DbkYjnPqZLzB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Model"
      ],
      "metadata": {
        "id": "ZBtt-3hiZfgO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# VIT\n",
        "VIT = \"google/vit-base-patch16-224-in21k\""
      ],
      "metadata": {
        "id": "QgVCIwdgZg4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup"
      ],
      "metadata": {
        "id": "UPLYNnImZiLF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vitImageProcessor = ViTImageProcessor.from_pretrained(VIT)"
      ],
      "metadata": {
        "id": "omhajUEHZRgz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vitModel = ViTForImageClassification.from_pretrained(\n",
        "    VIT,\n",
        "    num_labels=2,\n",
        "    label2id=label2id,\n",
        "    id2label=id2label,\n",
        "    ignore_mismatched_sizes = True, # provide this in case you're planning to fine-tune an already fine-tuned checkpoint\n",
        ")"
      ],
      "metadata": {
        "id": "y04SNbYuITyb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vitModel"
      ],
      "metadata": {
        "id": "UiQUna-6md0Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vitModel.config"
      ],
      "metadata": {
        "id": "seJxr_J6gTex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the training transforms\n",
        "dataset[\"train\"].set_transform(imageTransform(vitImageProcessor))\n",
        "# Set the validation transforms\n",
        "dataset[\"validate\"].set_transform(valImageTransform(vitImageProcessor))\n",
        "# Set the test transforms\n",
        "dataset[\"test\"].set_transform(valImageTransform(vitImageProcessor))"
      ],
      "metadata": {
        "id": "d-oG1yMDRTgw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "6hcrItEtVzOe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "args = TrainingArguments(\n",
        "    remove_unused_columns=False,\n",
        "    output_dir=\"./results/Dataset1/vit2\",\n",
        "    eval_strategy = \"epoch\",\n",
        "    save_strategy = \"epoch\",\n",
        "    learning_rate=5e-5,\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=32,\n",
        "    num_train_epochs=5,\n",
        "    logging_steps=10,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1\",\n",
        "    logging_dir='./logs',\n",
        "    weight_decay=0.01,\n",
        "    lr_scheduler_type='linear',\n",
        "    save_total_limit=1,\n",
        "    push_to_hub=True,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=vitModel,\n",
        "    args=args,\n",
        "    train_dataset=dataset[\"train\"],\n",
        "    eval_dataset=dataset[\"validate\"],\n",
        "    tokenizer=vitImageProcessor,\n",
        "    compute_metrics=compute_metrics,\n",
        "    data_collator=batch_sampler,\n",
        ")"
      ],
      "metadata": {
        "id": "5qaN0IEsZptt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train"
      ],
      "metadata": {
        "id": "Fv-R5BA7Kd41"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine-tune the model\n",
        "train_results = trainer.train()"
      ],
      "metadata": {
        "id": "zZbOQ66gS3nT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kwargs = {\n",
        "    \"finetuned_from\": \"VIT\",\n",
        "    \"tasks\": \"image-classification\",\n",
        "    \"dataset\": 'Mammogram V1',\n",
        "    \"tags\": ['image-classification', 'breast cancer'],\n",
        "}\n",
        "\n",
        "if args.push_to_hub:\n",
        "    trainer.push_to_hub('VIT-fineTuned', **kwargs)\n",
        "else:\n",
        "    trainer.create_model_card(**kwargs)\n"
      ],
      "metadata": {
        "id": "UHRRm6OHkQ4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_results.metrics"
      ],
      "metadata": {
        "id": "hlRzRtAI8ORn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model()\n",
        "trainer.log_metrics(\"train\", train_results.metrics)\n",
        "trainer.save_metrics(\"train\", train_results.metrics)\n",
        "trainer.save_state()"
      ],
      "metadata": {
        "id": "kI3Ize61TFrl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# trainer.state.log_history"
      ],
      "metadata": {
        "id": "lfA8w8kx5UMZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = pd.DataFrame(trainer.state.log_history)\n",
        "history.head(5)"
      ],
      "metadata": {
        "id": "zElVn6Bb5Y44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history.to_csv('Dataset1-ViT.csv')"
      ],
      "metadata": {
        "id": "i5aXniRkN_-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "history.plot(kind='line', x='learning_rate', y='epoch')"
      ],
      "metadata": {
        "id": "JE2e8usiHZTu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "history.plot(kind='line', x='learning_rate', y='loss')"
      ],
      "metadata": {
        "id": "6ElFYqJonuah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history.plot(kind='line', x='epoch', y='loss')"
      ],
      "metadata": {
        "id": "-XKFfV_weUEL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "history.plot(kind='line', x='epoch', y='eval_loss')"
      ],
      "metadata": {
        "id": "0LCaabyXeWsY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = trainer.predict(dataset['test'])\n",
        "print(outputs.metrics)"
      ],
      "metadata": {
        "id": "5FNDOstl2xt7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "y_true = outputs.label_ids\n",
        "y_pred = outputs.predictions.argmax(1)\n",
        "\n",
        "labels = ['Malignant', 'Benign']\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
        "disp.plot()"
      ],
      "metadata": {
        "id": "qIcTmtn52rnp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming y_true are the true labels and y_scores are the predicted probabilities\n",
        "y_true = outputs.label_ids\n",
        "y_scores = outputs.predictions.argmax(1)\n",
        "\n",
        "# Calculate the ROC curve\n",
        "fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n",
        "\n",
        "# Calculate AUC\n",
        "auc_score = roc_auc_score(y_true, y_scores)\n",
        "print(f'AUC: {auc_score}')\n",
        "\n",
        "# Plot the ROC curve\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {auc_score:.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC)')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3-ZbB2iaZcgh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SWIN-V2 model"
      ],
      "metadata": {
        "id": "bd9kRjJVZNXn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Model"
      ],
      "metadata": {
        "id": "YUu1v2ws6bCl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SWIN-V2\n",
        "SwinV2 = \"microsoft/swinv2-base-patch4-window8-256\""
      ],
      "metadata": {
        "id": "0iH7w0zDZR10"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup"
      ],
      "metadata": {
        "id": "7FJJZirx6efa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SwinV2ImageProcessor  = AutoImageProcessor.from_pretrained(SwinV2)"
      ],
      "metadata": {
        "id": "COzRD8n96cyd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "swinV2Model = AutoModelForImageClassification.from_pretrained(\n",
        "    SwinV2,\n",
        "    label2id=label2id,\n",
        "    id2label=id2label,\n",
        "    ignore_mismatched_sizes = True,\n",
        ")"
      ],
      "metadata": {
        "id": "jPhrE50K6yY_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# swinV2Model"
      ],
      "metadata": {
        "id": "70ooj8Ql7jLs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# swinV2Model.config"
      ],
      "metadata": {
        "id": "LA3NJVlEh_zr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the training transforms\n",
        "dataset['train'].set_transform(imageTransform(SwinV2ImageProcessor))\n",
        "# Set the validation transforms\n",
        "dataset['validate'].set_transform(valImageTransform(SwinV2ImageProcessor))\n",
        "# Set the test transforms\n",
        "dataset['test'].set_transform(valImageTransform(SwinV2ImageProcessor))"
      ],
      "metadata": {
        "id": "liQY42hbY9hn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    remove_unused_columns=False,\n",
        "    output_dir=\"./results/swinV2-Mammmogram-V1\",\n",
        "    eval_strategy = \"epoch\",\n",
        "    save_strategy = \"epoch\",\n",
        "    learning_rate=5e-5,\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=32,\n",
        "    num_train_epochs=10, #IDEAL NUMBER IS 3/4\n",
        "    weight_decay=0.01,\n",
        "    logging_steps=10,\n",
        "    logging_dir=\"./logs\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1\",\n",
        "    # push_to_hub=True,\n",
        "    lr_scheduler_type='linear',\n",
        "    save_total_limit=1,\n",
        ")\n",
        "\n",
        "# Instantiate the Trainer object\n",
        "trainer = Trainer(\n",
        "    model=swinV2Model,\n",
        "    args=training_args,\n",
        "    data_collator=batch_sampler,\n",
        "    compute_metrics=compute_metrics,\n",
        "    train_dataset=dataset['train'],\n",
        "    eval_dataset=dataset['validate'],\n",
        "    tokenizer=SwinV2ImageProcessor,\n",
        ")"
      ],
      "metadata": {
        "id": "5lpl6mIF7jIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train"
      ],
      "metadata": {
        "id": "WBkuW0eVaiX9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine-tune the model\n",
        "swinTrainResult = trainer.train()"
      ],
      "metadata": {
        "id": "eiZ-xEk5aiYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kwargs = {\n",
        "    \"finetuned_from\": \"swinv2\",\n",
        "    \"tasks\": \"image-classification\",\n",
        "    \"dataset\": 'Mammogram V1',\n",
        "    \"tags\": ['image-classification', 'breast cancer'],\n",
        "}\n",
        "\n",
        "# if training_args.push_to_hub:\n",
        "trainer.push_to_hub('SwinV2-finetuned', **kwargs)\n",
        "# else:\n",
        "#     trainer.create_model_card(**kwargs)"
      ],
      "metadata": {
        "id": "sbxezQC_2IV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r '/content/results' /content/drive/MyDrive/Data/Sept"
      ],
      "metadata": {
        "id": "qwktVm-kq7up"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "swinTrainResult.metrics"
      ],
      "metadata": {
        "id": "VqGtJi_RiWdI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model()\n",
        "trainer.log_metrics(\"train\", swinTrainResult.metrics)\n",
        "trainer.save_metrics(\"train\", swinTrainResult.metrics)\n",
        "trainer.save_state()"
      ],
      "metadata": {
        "id": "kenfoj5tiTza"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.state.log_history"
      ],
      "metadata": {
        "id": "sRQPL2AgaiYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = pd.DataFrame(trainer.state.log_history)\n",
        "history.head(5)"
      ],
      "metadata": {
        "id": "0NgFofOzaiYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history.to_csv('Dataset1-SwinV2.csv')"
      ],
      "metadata": {
        "id": "03MDlQT6oRy7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SwinMetrics = trainer.evaluate(val_data)\n",
        "# trainer.log_metrics(\"eval\", SwinMetrics)\n",
        "# trainer.save_metrics(\"eval\", SwinMetrics)\n",
        "# print(f\"Evaluation results: {SwinMetrics}\")"
      ],
      "metadata": {
        "id": "SfFq-Vg-NvcK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# @title learning_rate vs epoch\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "history.plot(kind='line', x='learning_rate', y='epoch')"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "id": "0F7ECzMHaiYH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "history.plot(kind='line', x='learning_rate', y='loss')"
      ],
      "metadata": {
        "id": "JF6hSyEcnouZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "history.plot(kind='line', x='epoch', y='loss')"
      ],
      "metadata": {
        "id": "tt42nn4JKb27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title accuracy vs epoch\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "history.plot(kind='line', x='eval_accuracy', y='epoch')"
      ],
      "metadata": {
        "id": "RhceM9XOofiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "swinOutputs = trainer.predict(dataset['test'])\n",
        "print(swinOutputs.metrics)"
      ],
      "metadata": {
        "id": "REgruGH_W4ai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "y_true = swinOutputs.label_ids\n",
        "y_pred = swinOutputs.predictions.argmax(1)\n",
        "\n",
        "labels = ['Malignant', 'Benign']\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
        "disp.plot()"
      ],
      "metadata": {
        "id": "hDp5ekFPqMj3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming y_true are the true labels and y_scores are the predicted probabilities\n",
        "y_true = swinOutputs.label_ids\n",
        "y_scores = swinOutputs.predictions.argmax(1)\n",
        "\n",
        "# Calculate the ROC curve\n",
        "fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n",
        "\n",
        "# Calculate AUC\n",
        "auc_score = roc_auc_score(y_true, y_scores)\n",
        "print(f'AUC: {auc_score}')\n",
        "\n",
        "# Plot the ROC curve\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {auc_score:.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC)')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ToPjC7wEOXfO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fast VIT model"
      ],
      "metadata": {
        "id": "1uy6jj8FZTSu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Model"
      ],
      "metadata": {
        "id": "WuJ8xPW-kMen"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fast VIT\n",
        "pretrained_fastVit = timm.create_model('fastvit_sa24.apple_in1k', pretrained=True, num_classes=2)"
      ],
      "metadata": {
        "id": "An64MQV65dWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_fastVit"
      ],
      "metadata": {
        "id": "NFDMx8o27rPy",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformed = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "])"
      ],
      "metadata": {
        "id": "G1Nz-bbDPybp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "item_tfms = [transforms.Resize((256,256)), transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])]\n",
        "# batch_tfms = [*aug_transforms(size=224, max_warp=0), transforms.functional.normalize]"
      ],
      "metadata": {
        "id": "j4rpBf_1EAYR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define functions to retrieve images and labels from the DataFrame\n",
        "def get_x(row): return row['image']  # Column containing PIL.Image objects\n",
        "def get_y(row): return row['cancer']  # Column containing labels\n",
        "\n",
        "# Define the DataBlock\n",
        "dblock = DataBlock(\n",
        "    blocks=(ImageBlock(PILImage), CategoryBlock),  # Handle PIL.Image and categorical labels\n",
        "    get_x=get_x,\n",
        "    get_y=get_y,\n",
        "    splitter=RandomSplitter(valid_pct=0.2, seed=999),  # 80-20 train-validation split with a seed\n",
        "    # item_tfms=item_tfms,  # Example item transformation\n",
        "    # batch_tfms=batch_tfms  # Example batch transformations\n",
        ")\n",
        "\n",
        "# Create DataLoaders\n",
        "dls = dblock.dataloaders(dfTrain, bs=32)\n",
        "\n",
        "# Show a batch of images\n",
        "dls.show_batch(max_n=9, figsize=(6,6))"
      ],
      "metadata": {
        "id": "aMEgZ_N-D2X8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learner = vision_learner(dls, 'fastvit_sa24.apple_in1k', metrics=accuracy)\n",
        "learner.lr_find()"
      ],
      "metadata": {
        "id": "9IRc68uyFnvT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learner.fine_tune(5, 5e-4)"
      ],
      "metadata": {
        "id": "J984Ptdd78zs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learner.recorder.plot_loss()"
      ],
      "metadata": {
        "id": "qewYWo4Pm8IQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interp = ClassificationInterpretation.from_learner(learner)\n",
        "interp.plot_confusion_matrix()"
      ],
      "metadata": {
        "id": "v2jfHmRSDqKq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interp.most_confused(min_val=50)"
      ],
      "metadata": {
        "id": "k6k1dll3nali"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interp.plot_top_losses(9, figsize= (16,16))"
      ],
      "metadata": {
        "id": "H4I8IIn0njAJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learner.save('/content/Mammogram_FastViT')\n",
        "learner.export()\n",
        "!cp -r '/content/Mammogram_FastViT.pth' /content/drive/MyDrive/Data/"
      ],
      "metadata": {
        "id": "Ttv5_o0ly7ze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "KM7pA-VhiKJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import push_to_hub_fastai\n",
        "\n",
        "repo_id = \"Nicole-M/fastViT-Mammogram-V1\"\n",
        "\n",
        "push_to_hub_fastai(learner=learner, repo_id=repo_id)"
      ],
      "metadata": {
        "id": "cUB-mafiiMTY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Faster ViT model"
      ],
      "metadata": {
        "id": "6p1qb9e6Fzq9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load FasterViT model\n",
        "pretrainedFasterViT = create_model('faster_vit_3_224', pretrained=True, model_path=\"/content/drive/MyDrive/Pretrained-models/fastervit_3_224_1k.pth.tar\")\n",
        "\n",
        "# Print the model architecture\n",
        "print(model)"
      ],
      "metadata": {
        "id": "gjTEyJO0GQ2r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Modify the final layer for custom classification\n",
        "num_ftrs = pretrainedFasterViT.head.in_features\n",
        "pretrainedFasterViT.head = torch.nn.Linear(num_ftrs, 2)"
      ],
      "metadata": {
        "id": "EMdfTGvzHDSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Move the model to GPU if available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "pretrainedFasterViT = pretrainedFasterViT.to(device)"
      ],
      "metadata": {
        "id": "T3d5N10MHJTT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, dataframe):\n",
        "        self.dataframe = pd.DataFrame(dataframe)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image = self.dataframe.iloc[index, 0]\n",
        "        label = self.dataframe.iloc[index, 1]\n",
        "        # print(image.shape)\n",
        "        # print(label)\n",
        "        # image = transforms.ToPILImage()(image)\n",
        "        image = ConvertToRGB()(image)\n",
        "        # print(type(image))\n",
        "        image = transforms.ToTensor()(image)\n",
        "        image = transforms.Resize((224,224))(image)\n",
        "        image = transforms.RandomRotation(180)(image)\n",
        "        image = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])(image)\n",
        "        label = torch.tensor(label)\n",
        "        return image, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "data = CustomDataset(dataframe=dfTrain)\n",
        "trainDataloader = DataLoader(data, batch_size=32, shuffle=True )\n",
        "# for sample in trainDataloader:\n",
        "#     print(sample)\n",
        "#     break"
      ],
      "metadata": {
        "id": "X78Ti1sL1Oo5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomTestDataset(Dataset):\n",
        "    def __init__(self, dataframe):\n",
        "        self.dataframe = pd.DataFrame(dataframe)\n",
        "        print(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image = self.dataframe.iloc[index, 0]\n",
        "        label = self.dataframe.iloc[index, 1]\n",
        "        image = ConvertToRGB()(image)\n",
        "        image = transforms.ToTensor()(image)\n",
        "        image = transforms.Resize((224,224))(image)\n",
        "        image = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])(image)\n",
        "        label = torch.tensor(label)\n",
        "        return image, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "data = CustomTestDataset(dataframe=dfTest)\n",
        "testDataloader = DataLoader(data, batch_size=32, shuffle=True )\n",
        "# for sample in testDataloader:\n",
        "#     print(sample)\n",
        "#     break"
      ],
      "metadata": {
        "id": "l33zN-231fvG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Define loss function\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Define optimizer\n",
        "# optimizer = optim.SGD(pretrainedFasterViT.parameters(), lr=0.001, momentum=0.9)\n",
        "optimizer = optim.Adam(pretrainedFasterViT.parameters(), lr=0.0005)\n",
        "\n",
        "# Learning rate scheduler\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)"
      ],
      "metadata": {
        "id": "bXNYwxdcHJqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "num_epochs = 4\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "pretrainedFasterViT.to(device)\n",
        "\n",
        "train_losses = []  # To store the losses for plotting\n",
        "best_val_loss = float('inf')  # Initialize with a very large value\n",
        "y_pred = []\n",
        "y_true = []\n",
        "\n",
        "# Train the model\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    # Train the model on the training set\n",
        "    pretrainedFasterViT.train()\n",
        "\n",
        "    # Initialize the training loss accumulator to zero\n",
        "    training_loss = 0.0\n",
        "\n",
        "    for i, (image, labels) in enumerate(trainDataloader):\n",
        "        # Prepare data and send it to the proper device\n",
        "        image = image.to(device)\n",
        "        # print(image.shape)\n",
        "        labels = labels.float().to(device)\n",
        "\n",
        "        # Clear the gradients of all optimized parameters\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass: obtain model predictions for the input data\n",
        "        outputs = pretrainedFasterViT(image)\n",
        "\n",
        "        # Compute the loss between the model predictions and the true labels\n",
        "        loss = criterion(outputs, labels.long())\n",
        "\n",
        "        # Backward pass: compute gradients of the loss with respect to model parameters\n",
        "        loss.backward()\n",
        "\n",
        "        # Update model parameters using the computed gradients and the optimizer\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the training loss\n",
        "        training_loss += loss.item()\n",
        "\n",
        "    # Calculate average training loss\n",
        "    train_loss = training_loss / len(trainDataloader)\n",
        "    train_losses.append(train_loss)\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "    pretrainedFasterViT.eval()\n",
        "    val_loss = 0.0\n",
        "    correct_preds = 0\n",
        "    total_samples = 0\n",
        "    with torch.no_grad():\n",
        "        for image, labels in testDataloader:\n",
        "            # Prepare data and send it to the proper device\n",
        "            image = image.to(device)\n",
        "            labels = labels.float().to(device)\n",
        "\n",
        "            # Forward pass: obtain model predictions for the input data\n",
        "            outputs = pretrainedFasterViT(image.float())\n",
        "\n",
        "            # Compute the loss between the model predictions and the true labels\n",
        "            loss = criterion(outputs, labels.long())\n",
        "\n",
        "            # Update the validation loss\n",
        "            val_loss += loss.item()\n",
        "\n",
        "             # Round up and down to either 1 or 0\n",
        "            predicted = torch.round(outputs)\n",
        "            total_samples += labels.size(0)\n",
        "\n",
        "            # Calculate how many images were correctly classified\n",
        "            correct_preds += torch.sum(torch.all(torch.eq(predicted[:, 0], labels))).item()\n",
        "\n",
        "    output2 = (torch.max(torch.exp(predicted), 1)[1]).data.cpu().numpy()\n",
        "    y_pred.extend(output2) # Save Prediction\n",
        "\n",
        "    labels2 = labels.data.cpu().numpy()\n",
        "    y_true.extend(labels2) # Save Truth\n",
        "\n",
        "    # Calculate validation loss\n",
        "    val_loss /= len(testDataloader)\n",
        "\n",
        "    # Calculate validation accuracy\n",
        "    val_acc = correct_preds / total_samples * 100\n",
        "\n",
        "    # Print validation loss and accuracy\n",
        "    print(f\"Epoch [{epoch + 1}/{num_epochs}] Train Loss: {train_loss:.4f}  Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.2f}%\")\n",
        "\n",
        "    # Save the model if it performs better on validation set\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        torch.save(pretrainedFasterViT.state_dict(), f'/content/best_model_epoch_{epoch + 1}.pth')\n",
        "\n",
        "print('Finished Training')\n",
        "\n",
        "# Plotting the evolution of loss\n",
        "plt.plot(train_losses, label='Training Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Evolution of Training Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bp9gaMuPWsn_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "ConfusionMatrixDisplay(cm).plot()"
      ],
      "metadata": {
        "id": "k4GtugUGj126"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "torch.save(pretrainedFasterViT.state_dict(), '/content/faster_vit_Dataset1.pth')"
      ],
      "metadata": {
        "id": "70NcZvynP9Ta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r '/content/faster_vit_Dataset1.pth' /content/drive/MyDrive/Data/results"
      ],
      "metadata": {
        "id": "J1bR7VsVZV29"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save to Google Drive"
      ],
      "metadata": {
        "id": "z32dQwFwZmQT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !cp -r '/content/best_model_epoch_2.pth' /content/drive/MyDrive/Data/results"
      ],
      "metadata": {
        "id": "6CBYN4VEZgmN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}