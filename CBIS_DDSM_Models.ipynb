{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wi0jTM1Uj9h7"
      },
      "source": [
        "# Installations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uTvYgc4vc_XQ"
      },
      "outputs": [],
      "source": [
        "!pip install -q datasets transformers accelerate opendatasets evaluate fastervit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y-OCWUT2HwTX"
      },
      "outputs": [],
      "source": [
        "!pip install timm==0.9.12"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0n0BvdAEvaMQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "    device_name = torch.device(\"cuda\")\n",
        "else:\n",
        "    device_name = torch.device('cpu')\n",
        "print(\"Using {}.\".format(device_name))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface_hub[\"fastai\"]"
      ],
      "metadata": {
        "id": "ZB4XBd6SjZ3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PC9-f1TAkCzU"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w3JX0FzKkFK_"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset, DatasetDict, load_metric, Dataset\n",
        "from transformers import AutoImageProcessor, AutoFeatureExtractor, AutoModelForImageClassification, TrainingArguments, Trainer, ViTForImageClassification, ViTFeatureExtractor, ViTImageProcessor, Swinv2Model\n",
        "from torchvision import transforms\n",
        "from sklearn.metrics import accuracy_score, roc_curve, roc_auc_score\n",
        "from sklearn.utils import resample\n",
        "from sklearn.model_selection import train_test_split\n",
        "from fastai.vision.all import *\n",
        "from fastervit import create_model\n",
        "from torchvision.io import read_image\n",
        "from torchvision.io import ImageReadMode\n",
        "from torchvision.transforms import (\n",
        "    CenterCrop,\n",
        "    Compose,\n",
        "    Normalize,\n",
        "    RandomHorizontalFlip,\n",
        "    RandomResizedCrop,\n",
        "    Resize,\n",
        "    ToTensor,\n",
        ")\n",
        "import timm\n",
        "import evaluate\n",
        "import datasets\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import opendatasets as od\n",
        "import PIL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgJkpCq_S8eX"
      },
      "source": [
        "# Reusable Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l2_F1AP3S-kN"
      },
      "outputs": [],
      "source": [
        "def convert_to_dataset(data):\n",
        "    dataset = Dataset.from_pandas(data)\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R9QY4SSTD-fJ"
      },
      "outputs": [],
      "source": [
        "def featureExtractor(model):\n",
        "    print(\"Model :\", model)\n",
        "    return AutoFeatureExtractor.from_pretrained(model)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(labels, preds)\n",
        "\n",
        "   # Calculate precision, recall, and F1-score\n",
        "    precision = precision_score(labels, preds, average='weighted')\n",
        "    recall = recall_score(labels, preds, average='weighted')\n",
        "    f1 = f1_score(labels, preds, average='weighted')\n",
        "\n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1\n",
        "    }"
      ],
      "metadata": {
        "id": "ahnK2J0hrz5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V5n7jI8-SNgW"
      },
      "outputs": [],
      "source": [
        "def batch_sampler(examples):\n",
        "\n",
        "    pixel_values = torch.stack([example[\"pixel_values\"] for example in examples])\n",
        "    for i in range(len(examples)):\n",
        "      if examples[i][\"pathology\"] == 'MALIGNANT':\n",
        "          examples[i][\"pathology\"] = 1\n",
        "      elif examples[i][\"pathology\"] == 'BENIGN':\n",
        "          examples[i][\"pathology\"] = 0\n",
        "    labels = torch.tensor([example[\"pathology\"] for example in examples])\n",
        "    return {\"pixel_values\": pixel_values, \"labels\": labels}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V_ltCMYeokhB"
      },
      "outputs": [],
      "source": [
        "labels = [\"Benign\",\"Malignant\"]\n",
        "label2id, id2label = dict(), dict()\n",
        "for i, label in enumerate(labels):\n",
        "    label2id[label] = i\n",
        "    id2label[i] = label\n",
        "\n",
        "id2label[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S4-mdlQkp02S"
      },
      "outputs": [],
      "source": [
        "class ConvertToRGB(Transform):\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def encodes(self, x: PIL.Image.Image) -> PIL.Image.Image:\n",
        "        return x.convert('RGB')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCjOLGEL_pyp"
      },
      "source": [
        "# Import Clean Data from Hugging face"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9NEc3UZil8Gm"
      },
      "outputs": [],
      "source": [
        "dataset = load_dataset(\"Nicole-M/Dataset2\")\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds_train_devtest = dataset['test'].train_test_split(test_size=0.5, seed=42)\n",
        "\n",
        "dataset = DatasetDict({\n",
        "    'train': dataset['train'],\n",
        "    'valid': ds_train_devtest['train'],\n",
        "    'test': ds_train_devtest['test']\n",
        "})\n",
        "dataset"
      ],
      "metadata": {
        "id": "LL3UvNvKZBGa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKdSvolArU1p"
      },
      "source": [
        "# Image Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wEpvnIJNtYDn"
      },
      "outputs": [],
      "source": [
        "# Transforms for pre-processing across a batch.\n",
        "class imageTransform:\n",
        "    columns = [\"image file path\", \"cropped image file path\"]\n",
        "\n",
        "    def __init__(self, featureExtractor):\n",
        "        size = (featureExtractor.size[\"height\"], featureExtractor.size[\"width\"])\n",
        "        self.transforms = transforms.Compose([\n",
        "            transforms.Resize(size),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.RandomHorizontalFlip(p=0.5),\n",
        "            transforms.RandomVerticalFlip(p=0.5),\n",
        "            transforms.RandomRotation(degrees=180),\n",
        "            # transforms.functional.to_pil_image(),\n",
        "            transforms.Normalize(mean=featureExtractor.image_mean, std=featureExtractor.image_std),\n",
        "        ])\n",
        "\n",
        "    def __call__(self, example_batch):\n",
        "        image_path = example_batch[\"image file path\"][0]\n",
        "        image = transforms.functional.to_pil_image(matplotlib.image.imread(image_path))\n",
        "        example_batch[\"pixel_values\"] = [self.transforms(image.convert(\"RGB\")) for i in example_batch[\"image file path\"]]\n",
        "        return example_batch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[\"train\"][9]"
      ],
      "metadata": {
        "id": "m2Bq8lQKJHy1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sj9UVt8hYSNx"
      },
      "outputs": [],
      "source": [
        "# Transforms for pre-processing across a batch.\n",
        "class valImageTransform:\n",
        "    def __init__(self, featureExtractor):\n",
        "        size = (featureExtractor.size[\"height\"], featureExtractor.size[\"width\"])\n",
        "        self.transforms = transforms.Compose([\n",
        "            transforms.Resize(size),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=featureExtractor.image_mean, std=featureExtractor.image_std),\n",
        "        ])\n",
        "\n",
        "    def __call__(self, example_batch):\n",
        "        image_path = example_batch[\"image file path\"][0]\n",
        "        image = transforms.functional.to_pil_image(matplotlib.image.imread(image_path))\n",
        "        example_batch[\"pixel_values\"] = [self.transforms(image.convert(\"RGB\")) for i in example_batch[\"image file path\"]]\n",
        "        return example_batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pY-6A23QChhE"
      },
      "source": [
        "# VIT model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWSG644AChhG"
      },
      "source": [
        "Load Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_y-fAbiChhH"
      },
      "outputs": [],
      "source": [
        "# VIT\n",
        "VIT = \"google/vit-base-patch16-224-in21k\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MOD7esgChhI"
      },
      "source": [
        "Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AnJLzcPxChhI"
      },
      "outputs": [],
      "source": [
        "ViTImageProcessor = ViTImageProcessor.from_pretrained(VIT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y04SNbYuITyb"
      },
      "outputs": [],
      "source": [
        "VitModel = ViTForImageClassification.from_pretrained(\n",
        "    VIT,\n",
        "    num_labels=2,\n",
        "    label2id=label2id,\n",
        "    id2label=id2label,\n",
        "    ignore_mismatched_sizes = True, # provide this in case you're planning to fine-tune an already fine-tuned checkpoint\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UiQUna-6md0Y"
      },
      "outputs": [],
      "source": [
        "# VitModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "seJxr_J6gTex"
      },
      "outputs": [],
      "source": [
        "# VitModel.config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d-oG1yMDRTgw"
      },
      "outputs": [],
      "source": [
        "# Set the training transforms\n",
        "dataset[\"train\"].set_transform(imageTransform(ViTImageProcessor))\n",
        "# Set the validation transforms\n",
        "dataset[\"valid\"].set_transform(valImageTransform(ViTImageProcessor))\n",
        "dataset[\"test\"].set_transform(valImageTransform(ViTImageProcessor))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fv-R5BA7Kd41"
      },
      "source": [
        "Train"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "voZIrw-5upb7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cw31P8reChhN"
      },
      "outputs": [],
      "source": [
        "args = TrainingArguments(\n",
        "    remove_unused_columns=False,\n",
        "    output_dir=\"./results/Vit-CBIS\",\n",
        "    eval_strategy = \"epoch\",\n",
        "    save_strategy = \"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=5,\n",
        "    logging_steps=10,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1\",\n",
        "    logging_dir='./logs',\n",
        "    weight_decay=0.01,\n",
        "    lr_scheduler_type='linear',\n",
        "    save_total_limit=1,\n",
        "    # push_to_hub=True,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=VitModel,\n",
        "    args=args,\n",
        "    train_dataset=dataset[\"train\"],\n",
        "    eval_dataset=dataset[\"valid\"],\n",
        "    tokenizer=ViTImageProcessor,\n",
        "    compute_metrics=compute_metrics,\n",
        "    data_collator=batch_sampler,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zZbOQ66gS3nT"
      },
      "outputs": [],
      "source": [
        "# Fine-tune the model\n",
        "vitTrainResult = trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kwargs = {\n",
        "    \"finetuned_from\": \"VIT\",\n",
        "    \"tasks\": \"image-classification\",\n",
        "    \"dataset\": 'CBIS-DDSM',\n",
        "    \"tags\": ['image-classification', 'breast cancer'],\n",
        "}\n",
        "\n",
        "trainer.push_to_hub('VIT-fineTuned', **kwargs)\n",
        "trainer.create_model_card(**kwargs)\n"
      ],
      "metadata": {
        "id": "chOkstT3uh87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hlRzRtAI8ORn"
      },
      "outputs": [],
      "source": [
        "vitTrainResult.metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qi6JluDESrjf"
      },
      "outputs": [],
      "source": [
        "trainer.save_model()\n",
        "trainer.log_metrics(\"train\", vitTrainResult.metrics)\n",
        "trainer.save_metrics(\"train\", vitTrainResult.metrics)\n",
        "trainer.save_state()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mUS2AhD0Srjf"
      },
      "outputs": [],
      "source": [
        "# trainer.state.log_history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Azwv-aaSrjg"
      },
      "outputs": [],
      "source": [
        "history = pd.DataFrame(trainer.state.log_history)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history.to_csv('Dataset2-ViT.csv')"
      ],
      "metadata": {
        "id": "96zuLKUx3PSG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CwG2dpWoSrjg"
      },
      "outputs": [],
      "source": [
        "# # Evaluate the model\n",
        "# eval_results = trainer.evaluate(val_data)\n",
        "# trainer.log_metrics(\"eval\", eval_results)\n",
        "# trainer.save_metrics(\"eval\", eval_results)\n",
        "# print(f\"Evaluation results: {eval_results}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i23SNXucSrjh"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "history.plot(kind='line', x='learning_rate', y='epoch')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mOSIznBPSrjh"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "history.plot(kind='line', x='learning_rate', y='loss')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wK5CE5tqSrji"
      },
      "outputs": [],
      "source": [
        "history.plot(kind='line', x='epoch', y='loss')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LV59zcFvSrji"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "history.plot(kind='line', x='epoch', y='eval_accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OKthCug_Srjj"
      },
      "outputs": [],
      "source": [
        "outputs = trainer.predict(dataset[\"test\"])\n",
        "print(outputs.metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lsBwVPPlSrjj"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "y_true = outputs.label_ids\n",
        "y_pred = outputs.predictions.argmax(1)\n",
        "\n",
        "labels = [0,1]\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
        "disp.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-ZbB2iaZcgh"
      },
      "outputs": [],
      "source": [
        "# Assuming y_true are the true labels and y_scores are the predicted probabilities\n",
        "y_true = outputs.label_ids\n",
        "y_scores = outputs.predictions.argmax(1)\n",
        "\n",
        "# Calculate the ROC curve\n",
        "fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n",
        "\n",
        "# Calculate AUC\n",
        "auc_score = roc_auc_score(y_true, y_scores)\n",
        "print(f'AUC: {auc_score}')\n",
        "\n",
        "# Plot the ROC curve\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {auc_score:.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC)')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UZQUp4_qSrjk"
      },
      "outputs": [],
      "source": [
        "from numpy import arange\n",
        "\n",
        "# Load the training and validation loss dictionaries\n",
        "train_loss = trainer.state.log_history\n",
        "\n",
        "# Generate a sequence of integers to represent the epoch numbers\n",
        "epochs = range(1, 21)\n",
        "\n",
        "# Plot and label the training and validation loss values\n",
        "plt.plot(\"loss\", label='Training Loss')\n",
        "plt.plot(\"eval_loss\", label='Validation Loss')\n",
        "\n",
        "# Add in a title and axes labels\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "\n",
        "# Set the tick locations\n",
        "plt.xticks(arange(0, 21, 2))\n",
        "\n",
        "# Display the plot\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sb90NFxHChh1"
      },
      "source": [
        "# SWIN-V2 model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUu1v2ws6bCl"
      },
      "source": [
        "Load Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QVbuib1CChh2"
      },
      "outputs": [],
      "source": [
        "SwinV2 = \"microsoft/swinv2-base-patch4-window8-256\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FJJZirx6efa"
      },
      "source": [
        "Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "COzRD8n96cyd"
      },
      "outputs": [],
      "source": [
        "SwinImageProcessor  = AutoImageProcessor.from_pretrained(SwinV2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jPhrE50K6yY_"
      },
      "outputs": [],
      "source": [
        "SwinModel = AutoModelForImageClassification.from_pretrained(\n",
        "    SwinV2,\n",
        "    label2id=label2id,\n",
        "    id2label=id2label,\n",
        "    ignore_mismatched_sizes = True, # provide this in case you're planning to fine-tune an already fine-tuned checkpoint\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "70ooj8Ql7jLs"
      },
      "outputs": [],
      "source": [
        "# SwinModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LA3NJVlEh_zr"
      },
      "outputs": [],
      "source": [
        "# SwinModel.config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "liQY42hbY9hn"
      },
      "outputs": [],
      "source": [
        "# Set the training transforms\n",
        "dataset[\"train\"].set_transform(imageTransform(SwinImageProcessor))\n",
        "# Set the validation transforms\n",
        "dataset[\"valid\"].set_transform(valImageTransform(SwinImageProcessor))\n",
        "dataset[\"test\"].set_transform(valImageTransform(SwinImageProcessor))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBkuW0eVaiX9"
      },
      "source": [
        "Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5lpl6mIF7jIC"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    remove_unused_columns=False,\n",
        "    output_dir=\"./results/swinV2-CBIS\",\n",
        "    eval_strategy = \"epoch\",\n",
        "    save_strategy = \"epoch\",\n",
        "    learning_rate=3e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=5,\n",
        "    weight_decay=0.01,\n",
        "    logging_steps=10,\n",
        "    logging_dir=\"./logs\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1\",\n",
        "    # push_to_hub=True,\n",
        "    lr_scheduler_type='linear',\n",
        "    save_total_limit=1,\n",
        ")\n",
        "\n",
        "# Instantiate the Trainer object\n",
        "trainer = Trainer(\n",
        "    model=SwinModel,\n",
        "    args=training_args,\n",
        "    data_collator=batch_sampler,\n",
        "    compute_metrics=compute_metrics,\n",
        "    train_dataset=dataset[\"train\"],\n",
        "    eval_dataset=dataset[\"valid\"],\n",
        "    tokenizer=SwinImageProcessor,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eiZ-xEk5aiYG"
      },
      "outputs": [],
      "source": [
        "# Fine-tune the model\n",
        "swinTrainResult = trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kwargs = {\n",
        "    \"finetuned_from\": \"swinv2\",\n",
        "    \"tasks\": \"image-classification\",\n",
        "    \"dataset\": 'CBIS-DDSM',\n",
        "    \"tags\": ['image-classification', 'breast cancer'],\n",
        "}\n",
        "\n",
        "trainer.push_to_hub('SwinV2-fineTuned', **kwargs)\n",
        "trainer.create_model_card(**kwargs)\n"
      ],
      "metadata": {
        "id": "BAdbJ3_6_WJW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VqGtJi_RiWdI"
      },
      "outputs": [],
      "source": [
        "swinTrainResult.metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kenfoj5tiTza"
      },
      "outputs": [],
      "source": [
        "trainer.save_model()\n",
        "trainer.log_metrics(\"train\", swinTrainResult.metrics)\n",
        "trainer.save_metrics(\"train\", swinTrainResult.metrics)\n",
        "trainer.save_state()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sRQPL2AgaiYG"
      },
      "outputs": [],
      "source": [
        "# trainer.state.log_history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a32Pta7RaiYG"
      },
      "outputs": [],
      "source": [
        "# # Evaluate the model\n",
        "# eval_results = trainer.evaluate()\n",
        "# print(f\"Evaluation results: {eval_results}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0NgFofOzaiYG"
      },
      "outputs": [],
      "source": [
        "history = pd.DataFrame(trainer.state.log_history)\n",
        "history.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history.to_csv('Dataset2-SwinV2.csv')"
      ],
      "metadata": {
        "id": "kbNTVjdCAeki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SfFq-Vg-NvcK"
      },
      "outputs": [],
      "source": [
        "# SwinMetrics = trainer.evaluate()\n",
        "# trainer.log_metrics(\"eval\", SwinMetrics)\n",
        "# trainer.save_metrics(\"eval\", SwinMetrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2QynKzJEqand"
      },
      "outputs": [],
      "source": [
        "# @title learning_rate vs epoch\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "history.plot(kind='scatter', x='learning_rate', y='epoch', s=32, alpha=.8)\n",
        "plt.gca().spines[['top', 'right',]].set_visible(False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0F7ECzMHaiYH"
      },
      "outputs": [],
      "source": [
        "# @title learning_rate vs epoch\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "history.plot(kind='line', x='learning_rate', y='epoch')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JF6hSyEcnouZ"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "history.plot(kind='line', x='learning_rate', y='loss')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tt42nn4JKb27"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "history.plot(kind='line', x='epoch', y='loss')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RhceM9XOofiL"
      },
      "outputs": [],
      "source": [
        "# @title accuracy vs epoch\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "history.plot(kind='line', x='loss', y='step')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "swinOutputs = trainer.predict(dataset[\"test\"])\n",
        "print(swinOutputs.metrics)"
      ],
      "metadata": {
        "id": "REgruGH_W4ai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "y_true = swinOutputs.label_ids\n",
        "y_pred = swinOutputs.predictions.argmax(1)\n",
        "\n",
        "labels = [0,1]\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
        "disp.plot()"
      ],
      "metadata": {
        "id": "hDp5ekFPqMj3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming y_true are the true labels and y_scores are the predicted probabilities\n",
        "y_true = swinOutputs.label_ids\n",
        "y_scores = swinOutputs.predictions.argmax(1)\n",
        "\n",
        "# Calculate the ROC curve\n",
        "fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n",
        "\n",
        "# Calculate AUC\n",
        "auc_score = roc_auc_score(y_true, y_scores)\n",
        "print(f'AUC: {auc_score}')\n",
        "\n",
        "# Plot the ROC curve\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {auc_score:.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC)')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ToPjC7wEOXfO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2eRvo9rNoxtS"
      },
      "source": [
        "# Import from CSV"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = od.download(\"https://www.kaggle.com/datasets/awsaf49/cbis-ddsm-breast-cancer-image-dataset\")"
      ],
      "metadata": {
        "id": "JOvhHUPOsWrb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Rename this downloaded dataset to \"dataset\" for FastVit to access images"
      ],
      "metadata": {
        "id": "_5zu9WYoLP3M"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZLcMu0aLp1df"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Data/cbisDdsm-Train.csv', header=None, index_col=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[0].replace('MALIGNANT', 1, inplace=True)\n",
        "df[0].replace('BENIGN', 0, inplace=True)\n",
        "df.head(5)"
      ],
      "metadata": {
        "id": "1sKySBCNLePZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfTest = df.tail(300)\n",
        "dfTest.shape"
      ],
      "metadata": {
        "id": "pVafyXTeiWeq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfTest.head(15)"
      ],
      "metadata": {
        "id": "KVaxkdErsCbW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(df.tail(300).index,inplace = True)\n",
        "df.shape"
      ],
      "metadata": {
        "id": "1QvLthZqiiRf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkINIk0lChhi"
      },
      "source": [
        "# Fast VIT model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuJ8xPW-kMen"
      },
      "source": [
        "Load Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "An64MQV65dWa"
      },
      "outputs": [],
      "source": [
        "# Fast VIT\n",
        "pretrained_fastVit = timm.create_model('fastvit_sa24.apple_in1k', pretrained=True, num_classes=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NFDMx8o27rPy"
      },
      "outputs": [],
      "source": [
        "# pretrained_fastVit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xO2goBMEPIF-"
      },
      "outputs": [],
      "source": [
        "item_tfms = [Resize((224,224))]\n",
        "            #  transforms.ToTensor()]\n",
        "# , ConvertToRGB(), transforms.ToPILImage(), Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "batch_tfms = [Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e1BFbU-f-BXk"
      },
      "outputs": [],
      "source": [
        "dls = ImageDataLoaders.from_df(path='/', df=df, valid_pct=0.2, label_col=0, fn_col=1, item_tfms=item_tfms, bs=16)\n",
        "                              #   batch_tfms=batch_tfms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Yt3Nc-579Bf"
      },
      "outputs": [],
      "source": [
        "from fastai.vision.all import *\n",
        "\n",
        "learner = vision_learner(dls, 'fastvit_sa24.apple_in1k', metrics=accuracy)\n",
        "learner.lr_find()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fYXlAMPzig7l"
      },
      "outputs": [],
      "source": [
        "learner.fine_tune(5, 1e-5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learner.recorder.plot_loss()"
      ],
      "metadata": {
        "id": "6v8mWBSLCR1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = ClassificationInterpretation.from_learner(learner)\n",
        "results.plot_confusion_matrix()"
      ],
      "metadata": {
        "id": "GyOHLI3n4U6T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results.most_confused(min_val=50)"
      ],
      "metadata": {
        "id": "k6k1dll3nali"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results.plot_top_losses(9, figsize= (16,16))"
      ],
      "metadata": {
        "id": "H4I8IIn0njAJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "W4tmozJU8Orr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import push_to_hub_fastai\n",
        "\n",
        "repo_id = \"Nicole-M/fastViT-CBIS\"\n",
        "\n",
        "push_to_hub_fastai(learner=learner, repo_id=repo_id)"
      ],
      "metadata": {
        "id": "Ett-56IUjkwM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wrV-UQkxmTUQ"
      },
      "outputs": [],
      "source": [
        "learner.save('/content/CBIS_DDSM_FastViT')\n",
        "learner.export()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r '/content/CBIS_DDSM_FastViT.pth' /content/drive/MyDrive/Data/"
      ],
      "metadata": {
        "id": "uw3JQpzT8kdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxSYTKe_Chhw"
      },
      "source": [
        "# Faster VIT model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIHRfB5zkBNg"
      },
      "source": [
        "Load Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gjTEyJO0GQ2r"
      },
      "outputs": [],
      "source": [
        "# Load FasterViT model\n",
        "model = create_model('faster_vit_3_224', pretrained=True, model_path=\"/content/drive/MyDrive/Pretrained-models/fastervit_3_224_1k.pth.tar\")\n",
        "\n",
        "# Print the model architecture\n",
        "# print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EMdfTGvzHDSN"
      },
      "outputs": [],
      "source": [
        "# Modify the final layer for custom classification\n",
        "num_ftrs = model.head.in_features\n",
        "model.head = torch.nn.Linear(num_ftrs, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T3d5N10MHJTT"
      },
      "outputs": [],
      "source": [
        "# Move the model to GPU if available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bXNYwxdcHJqs"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Define loss function\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Define optimizer\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Learning rate scheduler\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iEkel4FGs-0e"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, dataframe):\n",
        "        self.dataframe = pd.DataFrame(dataframe)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # path = \"/content/dataset/\"\n",
        "        imagePath = self.dataframe.iloc[index, 1]\n",
        "        label = self.dataframe.iloc[index, 0]\n",
        "        # print('/'+imagePath)\n",
        "        image = read_image('/'+ imagePath, mode=ImageReadMode.RGB)\n",
        "        image = transforms.Resize((224,224))(image)\n",
        "        image = transforms.RandomRotation(180)(image)\n",
        "        return image, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "data = CustomDataset(dataframe=df)\n",
        "trainDataloader = DataLoader(data, 16, shuffle=True )\n",
        "# for sample in trainDataloader:\n",
        "#     print(sample)\n",
        "#     break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w041TogVxYdD"
      },
      "outputs": [],
      "source": [
        "class CustomTestDataset(Dataset):\n",
        "    def __init__(self, dataframe):\n",
        "        self.dataframe = pd.DataFrame(dataframe)\n",
        "        # print(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        path = \"/\"\n",
        "        imagePath = self.dataframe.iloc[index, 1]\n",
        "        label = self.dataframe.iloc[index, 0]\n",
        "        image = read_image(path+imagePath, mode=ImageReadMode.RGB )\n",
        "        image = transforms.Resize((224,224))(image)\n",
        "        return image, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "data = CustomTestDataset(dataframe=dfTest)\n",
        "testDataloader = DataLoader(data, 16, shuffle=True)\n",
        "# for sample in testDataloader:\n",
        "#     print(sample)\n",
        "#     break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k8FTJeSLdu3g"
      },
      "outputs": [],
      "source": [
        "class_names = ['0', '1']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "num_epochs = 6\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "train_losses = []  # To store the losses for plotting\n",
        "best_val_loss = float('inf')  # Initialize with a very large value\n",
        "prediction_list = []\n",
        "label_list = []\n",
        "y_pred = []\n",
        "y_true = []\n",
        "\n",
        "# Train the model\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    # Train the model on the training set\n",
        "    model.train()\n",
        "\n",
        "    # Initialize the training loss accumulator to zero\n",
        "    training_loss = 0.0\n",
        "\n",
        "    for i, (image, labels) in enumerate(trainDataloader):\n",
        "        # Prepare data and send it to the proper device\n",
        "        image = image.to(device)\n",
        "        labels = labels.float().to(device)\n",
        "\n",
        "        # Clear the gradients of all optimized parameters\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass: obtain model predictions for the input data\n",
        "        outputs = model(image.float())\n",
        "\n",
        "        # Compute the loss between the model predictions and the true labels\n",
        "        loss = criterion(outputs, labels.long())\n",
        "\n",
        "        # Backward pass: compute gradients of the loss with respect to model parameters\n",
        "        loss.backward()\n",
        "\n",
        "        # Update model parameters using the computed gradients and the optimizer\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the training loss\n",
        "        training_loss += loss.item()\n",
        "\n",
        "    # Calculate average training loss\n",
        "    train_loss = training_loss / len(trainDataloader)\n",
        "    train_losses.append(train_loss)\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct_preds = 0\n",
        "    total_samples = 0\n",
        "    with torch.no_grad():\n",
        "        for image, labels in testDataloader:\n",
        "            # Prepare data and send it to the proper device\n",
        "            image = image.to(device)\n",
        "            labels = labels.float().to(device)\n",
        "\n",
        "            # Forward pass: obtain model predictions for the input data\n",
        "            outputs = model(image.float())\n",
        "\n",
        "            # Compute the loss between the model predictions and the true labels\n",
        "            loss = criterion(outputs, labels.long())\n",
        "\n",
        "            # Update the validation loss\n",
        "            val_loss += loss.item()\n",
        "\n",
        "             # Round up and down to either 1 or 0\n",
        "            predicted = torch.round(outputs)\n",
        "            total_samples += labels.size(0)\n",
        "\n",
        "            # Calculate how many images were correctly classified\n",
        "            correct_preds += torch.sum(torch.all(torch.eq(predicted, torch.argmax(labels.cpu(), dim=0)), dim=1)).item()\n",
        "\n",
        "            # Gather all predictions\n",
        "            prediction_list.extend(predicted.cpu())\n",
        "            label_list.extend(labels.cpu())\n",
        "\n",
        "\n",
        "    output2 = (torch.max(torch.exp(predicted), 1)[1]).data.cpu().numpy()\n",
        "    y_pred.extend(output2) # Save Prediction\n",
        "\n",
        "    labels2 = labels.data.cpu().numpy()\n",
        "    y_true.extend(labels2) # Save Truth\n",
        "\n",
        "\n",
        "    # Calculate validation loss\n",
        "    val_loss /= len(testDataloader)\n",
        "\n",
        "    # Calculate validation accuracy\n",
        "    val_acc = correct_preds / total_samples * 100\n",
        "\n",
        "    # Print validation loss and accuracy\n",
        "    print(f\"Epoch [{epoch + 1}/{num_epochs}] Train Loss: {train_loss:.4f}  Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.2f}%\")\n",
        "\n",
        "    # Save the model if it performs better on validation set\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        torch.save(model.state_dict(), f'/content/best_model_epoch_{epoch + 1}.pth')\n",
        "\n",
        "print('Finished Training')\n",
        "\n",
        "# Plotting the evolution of loss\n",
        "plt.plot(train_losses, label='Training Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Evolution of Training Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rXGUN7_TrRkT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "torch.save(model.state_dict(), 'fasterVit_model1.pth')"
      ],
      "metadata": {
        "id": "QaaLz3KGmUL7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "ConfusionMatrixDisplay(cm).plot()"
      ],
      "metadata": {
        "id": "TJFsjUmGGpK4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save to Google Drive"
      ],
      "metadata": {
        "id": "QEJOqZ7BBxxE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r '/content/faster_vit_custom_model.pth' /content/drive/MyDrive/Data/"
      ],
      "metadata": {
        "id": "xaC5IXxIB02e"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Wi0jTM1Uj9h7",
        "PC9-f1TAkCzU",
        "ijStOgA0rsb8",
        "TgJkpCq_S8eX",
        "2eRvo9rNoxtS",
        "cCjOLGEL_pyp",
        "gSl6r06NVAPT",
        "DveYwazbUSNv",
        "hkINIk0lChhi",
        "AxSYTKe_Chhw",
        "Sb90NFxHChh1"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "T4",
      "private_outputs": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}